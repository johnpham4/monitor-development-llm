groups:
  - name: fastapi_alerts
    rules:
      - alert: FastAPIServiceDown
        expr: up{job="fastapi-app"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "FastAPI service is down"
          description: "FastAPI service has been down for more than 1 minute."

      - alert: HighErrorRate
        expr: (sum(rate(chat_requests_total{status_code!~"2.."}[5m])) / sum(rate(chat_requests_total[5m]))) * 100 > 5
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }}% for more than 2 minutes."

      - alert: HighResponseTime
        expr: histogram_quantile(0.95, sum(rate(chat_request_duration_seconds_bucket[5m])) by (le)) > 10
        for: 3m
        labels:
          severity: warning
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }}s for more than 3 minutes."

      - alert: ModelNotLoaded
        expr: model_loaded == 0
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "AI Model is not loaded"
          description: "The AI model is not loaded and available for inference."

      - alert: HighMemoryUsage
        expr: (memory_usage_bytes / 1024 / 1024) > 2048
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value }}MB for more than 5 minutes."

      - alert: HighCPUUsage
        expr: cpu_usage_percent > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage"
          description: "CPU usage is {{ $value }}% for more than 5 minutes."

      - alert: SlowModelInference
        expr: histogram_quantile(0.95, sum(rate(model_inference_duration_seconds_bucket[5m])) by (le)) > 30
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Slow model inference"
          description: "95th percentile model inference time is {{ $value }}s for more than 2 minutes."

  - name: mlflow_alerts
    rules:
      - alert: MLflowServerDown
        expr: up{job="mlflow-server"} == 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "MLflow server is down"
          description: "MLflow server has been down for more than 2 minutes."